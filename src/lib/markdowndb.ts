import crypto from "crypto";
import fs from "fs";
import path from "path";
import knex, { Knex } from "knex";

import { recursiveWalkDir, parseFile, WikiLink } from "../utils/index.js";
import {
  File,
  MddbFile,
  Link,
  Tag,
  FileTag,
  MddbTag,
  MddbFileTag,
  MddbLink,
} from "./schema.js";

const defaultFilePathToUrl = (filePath: string) => {
  let url = filePath
    .replace(/\.(mdx|md)/, "")
    .replace(/\\/g, "/") // replace windows backslash with forward slash
    .replace(/(\/)?index$/, ""); // remove index from the end of the permalink
  url = url.length > 0 ? url : "/"; // for home page
  return encodeURI(url);
};

const resolveLinkToUrlPath = (link: string, sourceFilePath?: string) => {
  if (!sourceFilePath) {
    return link;
  }
  // needed to make path.resolve work correctly
  // becuase we store urls without leading slash
  const sourcePath = "/" + sourceFilePath;
  const dir = path.dirname(sourcePath);
  const resolved = path.resolve(dir, link);
  // remove leading slash
  return resolved.slice(1);
};

export class MarkdownDB {
  config: Knex.Config;
  db: Knex;

  constructor(config: Knex.Config) {
    this.config = config;
  }

  async init() {
    this.db = knex({ ...this.config, useNullAsDefault: true });
    return this;
  }

  async indexFolder({
    folderPath,
    // TODO support glob patterns
    ignorePatterns = [],
    pathToUrlResolver = defaultFilePathToUrl,
  }: {
    folderPath: string;
    ignorePatterns?: RegExp[];
    pathToUrlResolver?: (filePath: string) => string;
  }) {
    //  Temporary, we don't want to handle updates now
    //  so database is refreshed every time the folder
    //  is indexed
    await MddbFile.deleteTable(this.db);
    await MddbTag.deleteTable(this.db);
    await MddbFileTag.deleteTable(this.db);
    await MddbLink.deleteTable(this.db);

    await MddbFile.createTable(this.db);
    await MddbTag.createTable(this.db);
    await MddbFileTag.createTable(this.db);
    await MddbLink.createTable(this.db);

    const filePathsToIndex = recursiveWalkDir(folderPath);

    const filesToInsert: File[] = [];
    const fileTagsToInsert: FileTag[] = [];
    // TODO shouldn't available tags be explicitly defined in some config file
    // instead of being extracted from all files? I think it's better even from user perspective
    // as he can easily manage and see all the tags he is using
    // (he can qickly look up tag if he's not sure what term he was using in other files)
    // + it's easier to implement
    const tagsToInsert: Tag[] = [];
    const linksToInsert: Link[] = [];

    // TODO is there a better way to do this?
    // Temporary containter for storing links extracted from each file
    // as a map of file id -> extracted links.
    // This is used after all files have been parsed and added to filesToInsert
    // to resolve paths in links to target file ids
    const filesLinksMap: {
      [fileId: string]: {
        url: string;
        links: WikiLink[];
      };
    } = {};

    for (const filePath of filePathsToIndex) {
      if (ignorePatterns.some((pattern) => pattern.test(filePath))) {
        continue;
      }

      // id
      // TODO this can be autogenerated by database
      const encodedPath = Buffer.from(filePath, "utf-8").toString();
      const id = crypto.createHash("sha1").update(encodedPath).digest("hex");

      // extension
      const [, extension] = filePath.match(/.(\w+)$/) || [];

      if (!MddbFile.supportedExtensions.includes(extension)) {
        filesToInsert.push({
          _id: id,
          file_path: filePath,
          extension,
          url_path: null,
          filetype: null,
          metadata: null,
        });
        continue;
      }

      // url_path
      const pathRelativeToFolder = path.relative(folderPath, filePath);
      const urlPath = pathToUrlResolver(pathRelativeToFolder);

      // metadata, tags, links
      const source: string = fs.readFileSync(filePath, {
        encoding: "utf8",
        flag: "r",
      });

      const { metadata, links } = parseFile(source, {
        permalinks: filePathsToIndex,
      });
      const filetype = metadata?.type || null;

      // TODO is there a better way to do this?
      filesLinksMap[id] = {
        url: urlPath,
        links,
      };

      const tags = metadata?.tags || [];
      tags.forEach((tag: string) => {
        if (!tagsToInsert.some((t) => t.name === tag)) {
          tagsToInsert.push({ name: tag });
        }
        fileTagsToInsert.push({ file: id, tag });
      });

      filesToInsert.push({
        _id: id,
        file_path: filePath,
        extension,
        url_path: urlPath,
        filetype,
        metadata,
      });
    }

    Object.entries(filesLinksMap).forEach(([fileId, { url, links }]) => {
      links.forEach(({ linkSrc, linkType }) => {
        const destPath = resolveLinkToUrlPath(linkSrc, url);
        const destFile = filesToInsert.find(
          (file) => file.url_path === destPath
        );
        if (!destFile) {
          return;
        }
        const linkToInsert = {
          // _id: id,
          from: fileId,
          to: destFile._id,
          link_type: linkType,
        };
        linksToInsert.push(linkToInsert);
      });
    });

    if (filesToInsert.length >= 500) {
      for (let i = 0; i < filesToInsert.length; i += 500) {
        await MddbFile.batchInsert(this.db, filesToInsert.slice(i, i + 500));
      }
    } else {
      await MddbFile.batchInsert(this.db, filesToInsert);
    }

    // TODO  what happens if some of the files were not inserted?
    // I guess inserting tags or links with such files used as foreign keys will fail too,
    // but need to check

    if (tagsToInsert.length >= 500) {
      for (let i = 0; i < tagsToInsert.length; i += 500) {
        await MddbTag.batchInsert(this.db, tagsToInsert.slice(i, i + 500));
      }
    } else {
      await MddbTag.batchInsert(this.db, tagsToInsert);
    }

    if (fileTagsToInsert.length >= 500) {
      for (let i = 0; i < fileTagsToInsert.length; i += 500) {
        await MddbFileTag.batchInsert(
          this.db,
          fileTagsToInsert.slice(i, i + 500)
        );
      }
    } else {
      await MddbFileTag.batchInsert(this.db, fileTagsToInsert);
    }

    if (linksToInsert.length >= 500) {
      for (let i = 0; i < linksToInsert.length; i += 500) {
        await MddbLink.batchInsert(this.db, linksToInsert.slice(i, i + 500));
      }
    } else {
      await MddbLink.batchInsert(this.db, linksToInsert);
    }
  }

  async getFileById(id: string): Promise<MddbFile | null> {
    const file = await this.db.from("files").where("_id", id).first();
    return new MddbFile(file);
  }

  async getFileByUrl(url: string): Promise<MddbFile | null> {
    const file = await this.db
      .from("files")
      .where("url_path", encodeURI(url))
      .first();
    return new MddbFile(file);
  }

  async getFiles(query?: {
    folder?: string;
    filetypes?: string[];
    tags?: string[];
    extensions?: string[];
  }): Promise<MddbFile[]> {
    const { filetypes, tags, extensions, folder } = query || {};

    const files = await this.db
      // TODO join only if tags are specified ?
      .leftJoin("file_tags", "files._id", "file_tags.file")
      .where((builder) => {
        // TODO temporary solution before we have a proper way to filter files by and assign file types
        if (folder) {
          builder.whereLike("url_path", `${folder}/%`);
        }
        if (tags) {
          builder.whereIn("tag", tags);
        }

        if (extensions) {
          builder.whereIn("extension", extensions);
        }

        if (filetypes) {
          builder.whereIn("filetype", filetypes);
        }
      })
      .select("files.*")
      .from("files")
      .groupBy("_id");

    return files.map((file) => new MddbFile(file));
  }

  async getTags(): Promise<MddbTag[]> {
    const tags = await this.db("tags").select();
    return tags.map((tag) => new MddbTag(tag));
  }

  async getLinks(query?: {
    fileId: string;
    linkType?: "normal" | "embed";
    direction?: "forward" | "backward";
  }): Promise<MddbLink[]> {
    const { fileId, direction = "forward", linkType } = query || {};
    const joinKey = direction === "forward" ? "from" : "to";
    const where = {
      [joinKey]: fileId,
    };
    if (linkType) {
      where["link_type"] = linkType;
    }
    const dbLinks = await this.db
      .select("links.*")
      .from("links")
      .rightJoin("files", `links.${joinKey}`, "=", "files._id")
      .where(where);

    const links = dbLinks.map((link) => new MddbLink(link));
    return links;
  }

  _destroyDb() {
    this.db.destroy();
  }
}
